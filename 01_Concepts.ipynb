{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20815588",
   "metadata": {},
   "source": [
    "# Math and Concepts in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d031a",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Supervised VS Unsupervised Learning\n",
    "\n",
    "1. Supervised Learning: In supervised machine learning, a model makes predictions or decisions based on past or labeled data.\n",
    "2. Unsupervised Learning: In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.\n",
    "   1. Clustering\n",
    "   2. Association Rule Mining\n",
    "   3. Auto-encoders\n",
    "   4. Anomaly Detection\n",
    "3. Reinforcement Learning: Using reinforcement learning, the model can learn based on the rewards it received for its previous action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fea78d",
   "metadata": {},
   "source": [
    "-----\n",
    "### Classification VS Regression\n",
    "\n",
    "1. Classification: The target attribute $y$ is a discrete variable, such as a class label.\n",
    "2. Regression: The target attribute $y$ is a continuous variable, such as a real number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26822c",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Differentiate between correlation and covariance\n",
    "\n",
    "**Covariance shows you how the two variables differ, whereas correlation shows you how the two variables are related.**\n",
    "\n",
    "- Covariance is a statistical term that refers to a systematic relationship between two random variables in which a change in the other reflects a change in one variable.\n",
    "\n",
    "$${\\displaystyle \\operatorname {cov} (X,Y)=\\operatorname {E} \\left[(X-\\mu _{X})(Y-\\mu _{Y})\\right]}$$\n",
    "\n",
    "- Correlation is a measure that determines the degree to which two or more random variables move in sequence.\n",
    "\n",
    "$$\\rho _{XY}={\\frac {\\operatorname {cov} (X,Y)}{\\sigma _{X}\\sigma _{Y}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee56d3e",
   "metadata": {},
   "source": [
    "-----\n",
    "### Combat the curse of dimensionality\n",
    "\n",
    "1. Manual Feature Selection\n",
    "2. Principal Component Analysis (PCA)\n",
    "3. Multidimensional Scaling\n",
    "4. Locally linear embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91702a33",
   "metadata": {},
   "source": [
    "-----\n",
    "### What is Momentum (w.r.t NN optimization)?\n",
    "\n",
    "Momentum lets the optimization algorithm remembers its last step, and adds some proportion of it to the current step. This way, even if the algorithm is stuck in a flat region, or a small local minimum, it can get out and continue towards the true minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa7bbf",
   "metadata": {},
   "source": [
    "-----\n",
    "### What is the difference between Batch Gradient Descent and Stochastic Gradient Descent?\n",
    "\n",
    "Batch gradient descent computes the gradient using the whole dataset. This is great for convex, or relatively smooth error manifolds. In this case, we move somewhat directly towards an optimum solution, either local or global. Additionally, batch gradient descent, given an annealed learning rate, will eventually find the minimum located in it's basin of attraction.\n",
    "\n",
    "Stochastic gradient descent (SGD) computes the gradient using a single sample. SGD works well (Not well, I suppose, but better than batch gradient descent) for error manifolds that have lots of local maxima/minima. In this case, the somewhat noisier gradient calculated using the reduced number of samples tends to jerk the model out of local minima into a region that hopefully is more optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4bfdba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
